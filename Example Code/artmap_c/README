/*******************************************************************************
 * README v.1 (7/5/01)
 *
 * Description:
 *	Readme for artmap_c.zip
 *	See http://www.cns.bu.edu/~artmap for further details.
 * Authors:
 *	Suhas Chelian, Norbert Kopco
 ******************************************************************************/

/*******************************************************************************
 * Contents
 ******************************************************************************/
The attached archive artmap_c.zip contains a sample implementation of
the ARTMAP neural network, in many of its variations. The archive
contains the following files:

artmap.cpp	- implementation of the ARTMAP network
input.dat	- sample training set containing 1000 training
		  points for the Circle-in-the-Square problem 
		  (every row of this text file contains the input
		  values for one training pattern)
output.dat	- the file containing expected output classes for
		  the training set (every row of this text file
		  contains the class label for the corresponding
		  input in the file input.dat)
te_input.dat	- sample testing set containing 10000 testing
		  points for the Circle-in-the-Square problem
		  (format as in input.dat)
te_output.dat	- file containing expected output classes for the
		  testing set (format as in output.dat)
Makefile	- useful for compiling and zipping this package
README		- this file

The training and testing files (input.dat, output.dat, te_input.dat,
te_output.dat) must be placed into the same directory as the
executable code.

/*******************************************************************************
 * Compiling and Running
 ******************************************************************************/
The code, written in the C language, can be compiled and run on almost
any platform. To compile it under the Unix operating system use the
following command:

	gcc artmap.cpp -o artmap -lm

or, use the Makefile, by typing:

	make

To run it under under Unix, type:

	artmap

/*******************************************************************************
 * Configuration
 ******************************************************************************/
To choose which ARTMAP system you would like, make EXACTLY one of the
following flags 1: FUZZY_ARTMAP, ARTMAP_IC, ART_EMAP, DIST_ARTMAP.
From there, the system configuration is automatic.  See
http://www.cns.bu.edu/~artmap for the papers from which one can
compare the different versions of ARTMAP.

Please note that dARTMAP must use the Choice-by-difference signal
rule.  For now, all other ARTMAP variations also use the
Choice-by-difference signal rule, but they were originally
designed--and can be used--with the Weber signal rule.  If you
wish, you can change to using the Weber law by toggling the
DO_WEBER flag.  In addition, although MT- was not orignally
applied to Fuzzy ARTMAP or ART-EMAP, it can still be used.  If you
wish, you can change to MT+ (epsilon > 0), but then you lose the
ability to encode inconsistent case.  (Inconsistent cases are
cases when the same input is mapped to different outputs.)  
Similarly, although the Increased CAM Gradient was not originally
applied to ART-EMAP and ARTMAP-IC, it can still be used.  If you
wish, you can change to using the Simple CAM Gradient by toggling
the DO_TEST_SCG flag.

In addition, note that each implementation differs slightly from
the (Carpenter et al., 1998b) paper in that Theta is now defined
to be Theta from the paper - M.  This changes the Increased Cam
Gradient set { j | (2-alpha)M-Tj > 0 } to { j | M-Tj > 0 } (see
Step 2a in Training, and 2i in Testing); also Tu is now alpha*M,
not M.  These changes effect the dynamic range of the match
function, T, but not the algorithms overall behavior.

Before compilation of the code, the following parameters of the system
need to be specified:

M	Dimensionality of the input vectors in the training/testing
	set (not including complement coding)  

	Please note that input must be in the unit hypercube (all dimensions 
	are in the [0,1] interval).  The algorithm will
	not work properly if this is removed; for your convience, you can
	uncomment the lines that force unit hypercubing of input.

L	Number of output classes in the training/testing set (The
	classes are labeled by integers 1 to L, but 0 to L-1 by the code.)
EPOCHS	Number of training epochs (currently ignored)
TRAIN_N	The training set size (number of patterns in input.dat)
TEST_N  The testing set size (number of patterns in te_input.dat)

alpha		Parameter in the Choice-by-difference signal rule
old_beta	Parameter in the Weber Law signal rule
p		Power in the increased gradient CAM rule 
beta		Learning rate  
epsilon		Match tracking parameter  
rho_a_bar	ARTa baseline vigilance parameter  
T_u		F0 -> F2 signal for uncommited nodes
MAX_F2_SIZE	This constant defines the upper bound on the number of
			coding units in the Layer F2 (F2_SIZE also equals
			number of units in Layer F3.)

- Loosely speaking, alpha does the following:  Large values
will not recruit uncommited nodes as quickly.  This can also be achieved
by making T_u small with the Choice-by-difference signal rule.
- p determines the degree contrast enchancement in F2 for Simple CAM
gradient testing.  Large p are equivalent to Winner-take all (choice 
behavior), and small p lead to a more distributed activity pattern.  
Setting p < 1 is not recommended.
- See the papers at http://www.cns.bu.edu/~artmap for further information 
on how the parameters effect performance.

Common abbreviations you will run into include:

CBD	Choice-by-difference
WTA	Winner-take-all (choice)
ICG	Increased CAM gradient
IC	Instance counting
SCG	Simple CAM gradient

Lastly, the code has been written with goto's and minimal functions
for 2 reasons: 1.) it is easier to follow the flow of control (rather
than following the value of flags in nested loops), 2.) it is easier
to trace values (rather than always trace a value when a function is
called repeatedly in different contexts).

